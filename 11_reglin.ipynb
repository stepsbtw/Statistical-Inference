{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMykfI0rQ81iKcI4WgKZmlJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stepsbtw/Statistical-Inference/blob/main/11_reglin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REGRESSÃO LINEAR\n",
        "Técnica Estatística usada para modelar relação entre uma variável dependente (resposta) e uma ou mais variáveis independentes (preditoras) por meio de uma equação **linear**.\n",
        "\n",
        "O objetivo é encontrar a melhor linha reta (ou hiperplano, caso seja múltipla), que representa a relação entre as variáveis, premitindo assim **prever** ou **explicar** a variável dependente com base nas independentes."
      ],
      "metadata": {
        "id": "6XqnhjqrSL8t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REGRESSÃO LINEAR SIMPLES\n",
        "$$Y = \\beta_0 + \\beta_1X + ε$$\n",
        "- $β_0$ é o intercepto, que representa $Y$ quando $X$ é zero.\n",
        "- $β_1$ é o **coeficiente da variável $X$**, mede a mudança média em $Y$ associada a uma unidade de mudança em $X$.\n",
        "- $ϵ$ representa a variação não explicada pelo modelo.\n",
        "\n",
        "O objetivo é encontrar os valores de $β_0$ e $β_1$ que minimizam a **soma dos quadrados dos resíduos** (observado - previsto), essa será a melhor linha.\n",
        "\n",
        "## REGRESSÃO LINEAR MÚLTIPLA\n",
        "$$Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\ldots + \\beta_kX_k + \\epsilon$$\n",
        "\n",
        "**Suposições**:\n",
        "\n",
        "- Os resíduos do modelo (termos de erro) sejam independentes, tenham distribuição normal e variância constante.\n",
        "\n",
        "- Não há multicolinearidade significativa (alta correlação entre as variáveis independentes)\n",
        "\n",
        "- As relações entre as variáveis independentes e dependentes é linear."
      ],
      "metadata": {
        "id": "8uZky-joS14E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MÉTODO OLS (Ordinary Least Squares)\n",
        "O métodos dos mínimos quadrados ordinários é uma técnica para **estimar** os coeficientes de um modelo de regressão linear.\n",
        "\n",
        "**Objetivo: ** Encontrar a reta (hiperplano) que **melhor se ajusta aos dados**, minimizando as diferenças entre os valores observados e os previstos pelo modelo.\n",
        "\n",
        "$$\\hat{\\boldsymbol{\\beta}} = \\arg \\min_{\\boldsymbol{\\beta}} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "Onde $\\hat{y}_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$\n",
        "\n",
        "Amplamente usado por sua simplicidade.\n",
        "\n",
        "## OLS - Univariado\n",
        "$$y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i, \\quad i = 1, \\dots, n$$\n",
        "\n",
        "1. Função Perda\n",
        "$$J(\\beta_0, \\beta_1) = \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i)^2$$\n",
        "Queremos minimizar $J$ em relação a $\\beta_0$ e $\\beta_1$.\n",
        "\n",
        "2. Deriva e iguala a zero.\n",
        "Derivada parcial em relação a $\\beta_0$:\n",
        "\n",
        "$$\\frac{\\partial J}{\\partial \\beta_0} = -2 \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i) = 0$$\n",
        "\n",
        "$$\\Rightarrow \\sum y_i = n \\beta_0 + \\beta_1 \\sum x_i \\tag{1}$$\n",
        "\n",
        "Derivada parcial em relação a $\\beta_1$:\n",
        "\n",
        "$$\\frac{\\partial J}{\\partial \\beta_1} = -2 \\sum_{i=1}^n x_i (y_i - \\beta_0 - \\beta_1 x_i) = 0$$\n",
        "\n",
        "$$\\Rightarrow \\sum x_i y_i = \\beta_0 \\sum x_i + \\beta_1 \\sum x_i^2 \\tag{2}$$\n",
        "\n",
        "3. Resolver o Sistema\n",
        "\n",
        "Seja $\\bar{x} = \\frac{1}{n} \\sum x_i$ e $\\bar{y} = \\frac{1}{n} \\sum y_i$.\n",
        "\n",
        "De (1):\n",
        "$$\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}$$\n",
        "\n",
        "Substituindo em (2):\n",
        "$$\\sum x_i y_i = (\\bar{y} - \\beta_1 \\bar{x}) \\sum x_i + \\beta_1 \\sum x_i^2$$\n",
        "\n",
        "Então:\n",
        "$$\\hat{\\beta}_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}$$\n",
        "\n",
        "### Estimadores OLS\n",
        "$$\\boxed{\n",
        "\\hat{\\beta}_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}\n",
        "}\n",
        "\\quad \\text{e} \\quad\n",
        "\\boxed{\n",
        "\\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\n",
        "}$$\n",
        "\n",
        "- Coeficiente $\\beta_1$ mede a **inclinação da reta** ajustada, ou seja a variação média de $y$ pra cada unidade de aumneto em $x$.\n",
        "- O intercepto $\\beta_0$ é o valor esperado de $y$ quando $x = 0$.\n",
        "\n",
        "- Soma dos quadrados dos resíduos $\\text{SSE} = \\sum (y_i - \\hat{y}_i)^2 $ é minimizado."
      ],
      "metadata": {
        "id": "eBagMTgdUynK"
      }
    }
  ]
}